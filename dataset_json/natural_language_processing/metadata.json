[
  {
    "title": "Simulating the LOcal Web (SLOW) V. Thermodynamic Properties and Evolution of Local Galaxy Clusters",
    "outline": [
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H1",
        "text": "Observational data"
      },
      {
        "level": "H1",
        "text": "Simulations"
      },
      {
        "level": "H2",
        "text": "Constrained Initial Conditions"
      },
      {
        "level": "H2",
        "text": "Simulation Suite: SLOW"
      },
      {
        "level": "H2",
        "text": "Identification of Galaxy Clusters"
      },
      {
        "level": "H2",
        "text": "Analysis of the Intracluster Medium"
      },
      {
        "level": "H1",
        "text": "Local Galaxy Cluster Profiles and their Simulated Replicas"
      },
      {
        "level": "H2",
        "text": "The Perseus Cluster"
      },
      {
        "level": "H2",
        "text": "The Coma Cluster"
      },
      {
        "level": "H2",
        "text": "Abell 0085"
      },
      {
        "level": "H2",
        "text": "Abell 0119"
      },
      {
        "level": "H2",
        "text": "Abell 0644"
      },
      {
        "level": "H2",
        "text": "Abell 1644"
      },
      {
        "level": "H2",
        "text": "Abell 1795"
      },
      {
        "level": "H2",
        "text": "Abell A2029"
      },
      {
        "level": "H2",
        "text": "Abell 2319"
      },
      {
        "level": "H2",
        "text": "Abell 3158"
      },
      {
        "level": "H2",
        "text": "Abell 3266"
      },
      {
        "level": "H2",
        "text": "The Virgo  Cluster"
      },
      {
        "level": "H2",
        "text": "Successes and Limitations in Reproducing Local Clusters"
      },
      {
        "level": "H1",
        "text": "Connecting formation histories with late time cluster core states"
      },
      {
        "level": "H1",
        "text": "Conclusions"
      },
      {
        "level": "H1",
        "text": "Profile dependence on resolution"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15858v1",
    "url": "http://arxiv.org/abs/2507.15858v1"
  },
  {
    "title": "Diffusion Beats Autoregressive in Data-Constrained Settings",
    "outline": [
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H1",
        "text": "Related Work"
      },
      {
        "level": "H1",
        "text": "Method"
      },
      {
        "level": "H2",
        "text": "Preliminaries:"
      },
      {
        "level": "H2",
        "text": "Modeling Details for AR and Masked Diffusion"
      },
      {
        "level": "H2",
        "text": "Scaling Framework in Data-Constrained Settings"
      },
      {
        "level": "H2",
        "text": "Training setup"
      },
      {
        "level": "H1",
        "text": "Experiments"
      },
      {
        "level": "H2",
        "text": "Does Diffusion Beat AR in Data-Constrained Settings?"
      },
      {
        "level": "H2",
        "text": "Fitting Data-Constrained Scaling Laws"
      },
      {
        "level": "H2",
        "text": "When to Use Diffusion over AR?"
      },
      {
        "level": "H2",
        "text": "Downstream Results"
      },
      {
        "level": "H1",
        "text": "Discussion"
      },
      {
        "level": "H1",
        "text": "Limitations"
      },
      {
        "level": "H1",
        "text": "Conclusion"
      },
      {
        "level": "H1",
        "text": "Acknowledgement"
      },
      {
        "level": "H1",
        "text": "Broader Impacts"
      },
      {
        "level": "H1",
        "text": "Additional Results"
      },
      {
        "level": "H1",
        "text": "Model Architecture"
      },
      {
        "level": "H1",
        "text": "Early Loss Plateau"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15857v1",
    "url": "http://arxiv.org/abs/2507.15857v1"
  },
  {
    "title": "Latent Denoising Makes Good Visual Tokenizers",
    "outline": [
      {
        "level": "H1",
        "text": "Appendix"
      },
      {
        "level": "H1",
        "text": "Training and Inference Details"
      },
      {
        "level": "H2",
        "text": "Tokenizer"
      },
      {
        "level": "H2",
        "text": "Generative Models"
      },
      {
        "level": "H1",
        "text": "Additional Results"
      },
      {
        "level": "H1",
        "text": "Implementation"
      },
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H1",
        "text": "Discussion and Conclusion"
      },
      {
        "level": "H1",
        "text": "Acknowledgment"
      },
      {
        "level": "H1",
        "text": "Experiments"
      },
      {
        "level": "H2",
        "text": "Main Properties"
      },
      {
        "level": "H3",
        "text": "Properties of Latent Noising"
      },
      {
        "level": "H3",
        "text": "Properties of Masking"
      },
      {
        "level": "H3",
        "text": "Joint Denoising"
      },
      {
        "level": "H2",
        "text": "Generalization Experiments"
      },
      {
        "level": "H2",
        "text": "Benchmarking with Previous Systems"
      },
      {
        "level": "H1",
        "text": "Method"
      },
      {
        "level": "H2",
        "text": "Preliminaries of Generative Modeling"
      },
      {
        "level": "H2",
        "text": "Latent Denoising Tokenizers"
      },
      {
        "level": "H1",
        "text": "Related Work"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15856v1",
    "url": "http://arxiv.org/abs/2507.15856v1"
  },
  {
    "title": "Gemini 2.5 Pro Capable of Winning Gold at IMO 2025",
    "outline": [
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H1",
        "text": "Methods"
      },
      {
        "level": "H2",
        "text": "Pipeline"
      },
      {
        "level": "H2",
        "text": "Verifier"
      },
      {
        "level": "H1",
        "text": "Experiment Setup"
      },
      {
        "level": "H2",
        "text": "Step I Prompt"
      },
      {
        "level": "H2",
        "text": "Verification Prompt"
      },
      {
        "level": "H1",
        "text": "IMO 2025 Problems"
      },
      {
        "level": "H1",
        "text": "Gemini 2.5 Pro Solutions to the Problems"
      },
      {
        "level": "H2",
        "text": "Problem 1"
      },
      {
        "level": "H2",
        "text": "Problem 2"
      },
      {
        "level": "H2",
        "text": "Problem 3"
      },
      {
        "level": "H2",
        "text": "Problem 4"
      },
      {
        "level": "H2",
        "text": "Problem 5"
      },
      {
        "level": "H2",
        "text": "Problem 6"
      },
      {
        "level": "H1",
        "text": "Outlook"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15855v1",
    "url": "http://arxiv.org/abs/2507.15855v1"
  },
  {
    "title": "Overcast mornings and clear evenings in hot Jupiter exoplanet atmospheres",
    "outline": [
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H1",
        "text": "Methods"
      },
      {
        "level": "H2",
        "text": "Definition of morning and evening limbs"
      },
      {
        "level": "H2",
        "text": "Sample and instrument mode selection"
      },
      {
        "level": "H3",
        "text": "Photometric bands selection"
      },
      {
        "level": "H2",
        "text": "Data reduction"
      },
      {
        "level": "H3",
        "text": "Limb spectra fitting"
      },
      {
        "level": "H3",
        "text": "Empirical visualization of limb-limb asymmetry"
      },
      {
        "level": "H3",
        "text": "Comparing NIRISS SOSS with NIRSpec PRISM"
      },
      {
        "level": "H3",
        "text": "Mid-transit time uncertainties vs. limb spectra"
      },
      {
        "level": "H2",
        "text": "Empirical trends"
      },
      {
        "level": "H3",
        "text": "Asymmetry horizon"
      },
      {
        "level": "H2",
        "text": "1D \\texttt{PICASO"
      },
      {
        "level": "H1",
        "text": "Discussion"
      },
      {
        "level": "H2",
        "text": "Clear evenings and muted mornings"
      },
      {
        "level": "H2",
        "text": "Temperature difference between limbs"
      },
      {
        "level": "H2",
        "text": "Possible mechanisms"
      },
      {
        "level": "H3",
        "text": "Gravitational settling and stellar radiation pressure"
      },
      {
        "level": "H3",
        "text": "Atmospheric vertical flow"
      },
      {
        "level": "H3",
        "text": "Condensation and evaporation"
      },
      {
        "level": "H3",
        "text": "Downwell flow or Evaporation?"
      },
      {
        "level": "H3",
        "text": "Cloud or haze?"
      },
      {
        "level": "H3",
        "text": "Caveats"
      },
      {
        "level": "H1",
        "text": "Biasing atmospheric composition inference"
      },
      {
        "level": "H1",
        "text": "Limb Spectroscopy Metric (LSM)"
      },
      {
        "level": "H1",
        "text": "Conclusion"
      },
      {
        "level": "H1",
        "text": "Appendix A \\\\ \\texttt{picaso"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15854v1",
    "url": "http://arxiv.org/abs/2507.15854v1"
  },
  {
    "title": "SeC: Advancing Complex Video Object Segmentation via Progressive Concept Construction",
    "outline": [
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H1",
        "text": "Related work"
      },
      {
        "level": "H1",
        "text": "Method"
      },
      {
        "level": "H2",
        "text": "Preliminary study on current VOS"
      },
      {
        "level": "H2",
        "text": "Segement Concept model"
      },
      {
        "level": "H2",
        "text": "Discussion"
      },
      {
        "level": "H1",
        "text": "SeCVOS benchmark"
      },
      {
        "level": "H1",
        "text": "Experiments"
      },
      {
        "level": "H2",
        "text": "Implementation details"
      },
      {
        "level": "H2",
        "text": "Main results on SeCVOS"
      },
      {
        "level": "H2",
        "text": "Comparison on standard VOS benchmarks"
      },
      {
        "level": "H2",
        "text": "Ablation study"
      },
      {
        "level": "H2",
        "text": "Visualization"
      },
      {
        "level": "H1",
        "text": "Conclusion"
      },
      {
        "level": "H1",
        "text": "Supplementary Material Overview"
      },
      {
        "level": "H1",
        "text": "Details of SeCVOS"
      },
      {
        "level": "H1",
        "text": "Referring Video Object Segmentation on SeCVOS"
      },
      {
        "level": "H1",
        "text": "Additional Qualitative Results"
      },
      {
        "level": "H1",
        "text": "Broader Impacts"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15852v1",
    "url": "http://arxiv.org/abs/2507.15852v1"
  },
  {
    "title": "The Other Mind: How Language Models Exhibit Human Temporal Cognition",
    "outline": [
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H1",
        "text": "Related Works"
      },
      {
        "level": "H1",
        "text": "Methods"
      },
      {
        "level": "H2",
        "text": "Similarity Judgment Task"
      },
      {
        "level": "H2",
        "text": "Neural Coding"
      },
      {
        "level": "H2",
        "text": "Representational Structure"
      },
      {
        "level": "H2",
        "text": "Information Exposure"
      },
      {
        "level": "H1",
        "text": "Results"
      },
      {
        "level": "H2",
        "text": "Similarity Judgment Task"
      },
      {
        "level": "H2",
        "text": "Neural Coding Mechanism"
      },
      {
        "level": "H2",
        "text": "Representational Structure"
      },
      {
        "level": "H2",
        "text": "Information Exposure"
      },
      {
        "level": "H1",
        "text": "Discussion"
      },
      {
        "level": "H1",
        "text": "Conclusion"
      },
      {
        "level": "H1",
        "text": "Appendix"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15851v1",
    "url": "http://arxiv.org/abs/2507.15851v1"
  },
  {
    "title": "The Impact of Language Mixing on Bilingual LLM Reasoning",
    "outline": [
      {
        "level": "H1",
        "text": "Conclusion"
      },
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H1",
        "text": "Can we steer the model toward strategic language mixing?"
      },
      {
        "level": "H2",
        "text": "Probe-Guided Decoding"
      },
      {
        "level": "H2",
        "text": "Performance of Probe-Guided Decoding"
      },
      {
        "level": "H1",
        "text": "Do LLMs reason better or worse with language mixing?"
      },
      {
        "level": "H2",
        "text": "Constrained Decoding"
      },
      {
        "level": "H2",
        "text": "Constrained vs. Unconstrained Decoding"
      },
      {
        "level": "H1",
        "text": "Limitations"
      },
      {
        "level": "H1",
        "text": "Where does Language Mixing Occur?"
      },
      {
        "level": "H2",
        "text": "Detecting Code-Switches"
      },
      {
        "level": "H2",
        "text": "Tracing the Evolution of Language Mixing in LLMs"
      },
      {
        "level": "H2",
        "text": "Characterizing Code-Switching Behavior"
      },
      {
        "level": "H1",
        "text": "Related Work"
      },
      {
        "level": "H2",
        "text": "Code-Switching"
      },
      {
        "level": "H1",
        "text": "Appendix"
      },
      {
        "level": "H2",
        "text": "Overall Setup"
      },
      {
        "level": "H2",
        "text": "Evaluation datasets"
      },
      {
        "level": "H2",
        "text": "RLVR Triggers Language Mixing"
      },
      {
        "level": "H2",
        "text": "Rule-Based Code-Switch Detection"
      },
      {
        "level": "H2",
        "text": "Detailed Implementation of Constrained Decoding"
      },
      {
        "level": "H2",
        "text": "Probing for Beneficial Code-Switches"
      },
      {
        "level": "H2",
        "text": "Probe Performance and Utility"
      },
      {
        "level": "H2",
        "text": "Performance Comparison on AIME2024"
      },
      {
        "level": "H2",
        "text": "Examples of Language Mixing in QwQ-32B-Preview"
      },
      {
        "level": "H2",
        "text": "Examples of Probe-Guided Decoding"
      },
      {
        "level": "H2",
        "text": "Examples of Beneficial/ Harmful/ Neutral Code Switches"
      },
      {
        "level": "H2",
        "text": "Examples of probe-guided vs not guided generation"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15849v1",
    "url": "http://arxiv.org/abs/2507.15849v1"
  },
  {
    "title": "GUI-G$^2$: Gaussian Reward Modeling for GUI Grounding",
    "outline": [
      {
        "level": "H1",
        "text": "Conclusion"
      },
      {
        "level": "H1",
        "text": "Method"
      },
      {
        "level": "H2",
        "text": "Problem Formulation"
      },
      {
        "level": "H2",
        "text": "Gaussian Reward Modeling"
      },
      {
        "level": "H2",
        "text": "Reinforcement Learning with \\methodname"
      },
      {
        "level": "H1",
        "text": "Related Work"
      },
      {
        "level": "H2",
        "text": "GUI Agents"
      },
      {
        "level": "H2",
        "text": "Reinforcement Fine-Tuning"
      },
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H1",
        "text": "Experiments"
      },
      {
        "level": "H2",
        "text": "Experiment Setup"
      },
      {
        "level": "H2",
        "text": "Main Results"
      },
      {
        "level": "H2",
        "text": "Reward Design Analysis"
      },
      {
        "level": "H2",
        "text": "Ablation Studies"
      },
      {
        "level": "H1",
        "text": "Appendix"
      },
      {
        "level": "H2",
        "text": "Analysis of Spurious Rewards"
      },
      {
        "level": "H2",
        "text": "Evaluation Details"
      },
      {
        "level": "H2",
        "text": "Error Analysis"
      },
      {
        "level": "H2",
        "text": "Future Work"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15846v1",
    "url": "http://arxiv.org/abs/2507.15846v1"
  },
  {
    "title": "Quantum computational sensing using quantum signal processing, quantum neural networks, and Hamiltonian engineering",
    "outline": [
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H1",
        "text": "Quantum Computational Sensing"
      },
      {
        "level": "H2",
        "text": "Summary of main results"
      },
      {
        "level": "H1",
        "text": "Quantum computational sensing using qubit-based sensors"
      },
      {
        "level": "H2",
        "text": "QCS using a single qubit for binary classification tasks"
      },
      {
        "level": "H2",
        "text": "Dependence on task complexity"
      },
      {
        "level": "H2",
        "text": "QCS using multiple qubits: binary and multi-class discrimination of multi-dimensional signals"
      },
      {
        "level": "H2",
        "text": "QCS of spatiotemporal signals using multiple qubits"
      },
      {
        "level": "H2",
        "text": "Summary of QCS using qubit-only sensors"
      },
      {
        "level": "H1",
        "text": "Quantum Computational Sensing using bosonic sensors"
      },
      {
        "level": "H2",
        "text": "Function-approximation tasks"
      },
      {
        "level": "H2",
        "text": "QS approach: linear phase-preserving amplifier"
      },
      {
        "level": "H2",
        "text": "QCS approach: nonlinear amplifier"
      },
      {
        "level": "H2",
        "text": "Quantum computational-sensing advantage"
      },
      {
        "level": "H1",
        "text": "Quantum Computational Sensing using hybrid sensors"
      },
      {
        "level": "H1",
        "text": "Discussion and Outlook"
      },
      {
        "level": "H2",
        "text": "Overview of our work"
      },
      {
        "level": "H2",
        "text": "Experimental prospects and future research directions"
      },
      {
        "level": "H1",
        "text": "Data and code availability"
      },
      {
        "level": "H1",
        "text": "Author contributions"
      },
      {
        "level": "H1",
        "text": "Acknowledgements"
      },
      {
        "level": "H1",
        "text": "Appendices"
      },
      {
        "level": "H1",
        "text": "Appendices"
      },
      {
        "level": "H1",
        "text": "Classical postprocessing and error scaling with nonlinearity: unbiased estimation of nonlinear polynomials of a classical Gaussian random variable"
      },
      {
        "level": "H1",
        "text": "QCS of static signals using qubit-based quantum computational sensors"
      },
      {
        "level": "H2",
        "text": "Architectures for qubit-based quantum computational sensors of static signals"
      },
      {
        "level": "H2",
        "text": "Bayes (optimal) classifier for binary classification using a single qubit"
      },
      {
        "level": "H2",
        "text": "Approximate Gaussian classifier for binary classification using a single-qubit conventional quantum sensor"
      },
      {
        "level": "H2",
        "text": "Role of sampling noise in QCSA using a single-variable example"
      },
      {
        "level": "H2",
        "text": "QCSA vs. task complexity for simplified tasks: approximate analytic error probability for a single-qubit conventional quantum sensor"
      },
      {
        "level": "H2",
        "text": "QCSA vs. task complexity for more general tasks"
      },
      {
        "level": "H2",
        "text": "Multi-variate sensing: comparing quantum computational sensors against multiple Ramsey interferometers"
      },
      {
        "level": "H2",
        "text": "QCSA for multi-variable binary discrimination tasks using a single qubit"
      },
      {
        "level": "H1",
        "text": "QCS of spatiotemporal signals using qubit-based quantum computational sensors"
      },
      {
        "level": "H2",
        "text": "Dataset and classification task"
      },
      {
        "level": "H2",
        "text": "Dataset preprocessing"
      },
      {
        "level": "H2",
        "text": "Quantum Neural Network architecture for QCS"
      },
      {
        "level": "H2",
        "text": "Training details"
      },
      {
        "level": "H2",
        "text": "Additional results"
      },
      {
        "level": "H1",
        "text": "QCS for function approximation using bosonic quantum computational sensors"
      },
      {
        "level": "H2",
        "text": "Architecture: $\\Udec$ and quadrature measurements"
      },
      {
        "level": "H3",
        "text": "Initial state and expectation values"
      },
      {
        "level": "H3",
        "text": "Heterodyne measurements"
      },
      {
        "level": "H2",
        "text": "Function approximation task: target polynomials $\\Ft$ and expected mean-squared-error as a metric"
      },
      {
        "level": "H2",
        "text": "Nonlinear function approximation using a linear phase-preserving amplifier"
      },
      {
        "level": "H3",
        "text": "Quantum dynamics of a linear phase-preserving amplifier"
      },
      {
        "level": "H3",
        "text": "Two-variable function estimation using heterodyne measurement"
      },
      {
        "level": "H2",
        "text": "Nonlinear function approximation using a nonlinear amplifier"
      },
      {
        "level": "H3",
        "text": "Quantum dynamics of a nonlinear amplifier"
      },
      {
        "level": "H3",
        "text": "Two-variable function estimation using heterodyne measurement"
      },
      {
        "level": "H2",
        "text": "Worked example: \\XOR{"
      },
      {
        "level": "H3",
        "text": "Conventional QS approach: phase-preserving linear amplifier"
      },
      {
        "level": "H3",
        "text": "QCS approach: nonlinear amplifier"
      },
      {
        "level": "H2",
        "text": "QS and QCS protocols: 1D polynomial approximation"
      },
      {
        "level": "H2",
        "text": "QS and QCS protocols: Higher-order \\spirals{"
      },
      {
        "level": "H1",
        "text": "QCS using hybrid quantum computational sensors"
      },
      {
        "level": "H2",
        "text": "Architecture for hybrid qubit-cavity quantum computational sensors"
      },
      {
        "level": "H2",
        "text": "Hilbert space truncation"
      },
      {
        "level": "H2",
        "text": "Comparing hybrid quantum computational sensors against phase-preserving amplifiers"
      },
      {
        "level": "H1",
        "text": "General training details"
      },
      {
        "level": "H2",
        "text": "Trainable models, classical postprocessing, and loss functions"
      },
      {
        "level": "H3",
        "text": "Differentiable models and measurement results"
      },
      {
        "level": "H3",
        "text": "Training datasets and loss functions"
      },
      {
        "level": "H3",
        "text": "Classical postprocessing"
      },
      {
        "level": "H2",
        "text": "Performance of training using finitely-sampled measurements"
      },
      {
        "level": "H2",
        "text": "Number of measurement samples for training versus inference"
      },
      {
        "level": "H1",
        "text": "Limitations of classical postprocessing in the presence of sampling noise"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15845v1",
    "url": "http://arxiv.org/abs/2507.15845v1"
  },
  {
    "title": "Hierarchical Budget Policy Optimization for Adaptive Reasoning",
    "outline": [
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H1",
        "text": "Related Works"
      },
      {
        "level": "H1",
        "text": "Method"
      },
      {
        "level": "H1",
        "text": "Experiments"
      },
      {
        "level": "H1",
        "text": "Analysis"
      },
      {
        "level": "H1",
        "text": "Conclusion"
      },
      {
        "level": "H2",
        "text": "Analysis of Hierarchical Structure"
      },
      {
        "level": "H2",
        "text": "Reasoning Pattern Analysis"
      },
      {
        "level": "H2",
        "text": "Experimental Setup"
      },
      {
        "level": "H2",
        "text": "Main Results"
      },
      {
        "level": "H2",
        "text": "Hierarchical Budget Exploration"
      },
      {
        "level": "H2",
        "text": "Budget-Aware Reward Design"
      },
      {
        "level": "H3",
        "text": "Intra-Budget Reward Function"
      },
      {
        "level": "H3",
        "text": "Inter-Budget Reward Differentiation"
      },
      {
        "level": "H2",
        "text": "Training Procedure"
      },
      {
        "level": "H2",
        "text": "Efficient Reasoning"
      },
      {
        "level": "H2",
        "text": "Adaptive Reasoning"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15844v1",
    "url": "http://arxiv.org/abs/2507.15844v1"
  },
  {
    "title": "Closure Conversion, Flat Environments, and the Complexity of Abstract Machines",
    "outline": [
      {
        "level": "H1",
        "text": "Part 3: Complexity of the \\TAM, or, Tuples Raise the Overhead"
      },
      {
        "level": "H1",
        "text": "Part 1: The Source Calculus \\texorpdfstring{$\\soucal$"
      },
      {
        "level": "H1",
        "text": "Related Work and Conclusions"
      },
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H1",
        "text": "Part 3 Preliminaries: Sharing, Size Explosion, and the Complexity of Abstract Machines"
      },
      {
        "level": "H1",
        "text": "Part 2: the \\LTAM for the Intermediate Calculus"
      },
      {
        "level": "H1",
        "text": "Part 2: the \\LTAM for \\texorpdfstring{$\\intcal$"
      },
      {
        "level": "H1",
        "text": "Part 1: the Intermediate Calculus \\texorpdfstring{$\\intcal$"
      },
      {
        "level": "H1",
        "text": "Preliminaries: %the Call-by-Value $\\l$-Calculus $\\cbvcal$, Plus Some Notations"
      },
      {
        "level": "H1",
        "text": "Proofs and Auxiliary Notions of \\refsect{target-calculus"
      },
      {
        "level": "H1",
        "text": "Conclusions"
      },
      {
        "level": "H1",
        "text": "Appendix"
      },
      {
        "level": "H1",
        "text": "Part 3: Complexity of the \\TTAM, or, Closure Conversion Preserves the Overhead"
      },
      {
        "level": "H1",
        "text": "Part 2 Preliminaries: Abstract Machines"
      },
      {
        "level": "H1",
        "text": "Part 2: the Tupled Abstract Machine for the Source Calculus"
      },
      {
        "level": "H1",
        "text": "Part 2: the \\TAM for \\texorpdfstring{$\\soucal$"
      },
      {
        "level": "H1",
        "text": "Proofs and Auxiliary Notions of \\refsect{prelim-am"
      },
      {
        "level": "H1",
        "text": "Proofs and Auxiliary Notions of \\refsect{TAM"
      },
      {
        "level": "H1",
        "text": "Proofs and Auxiliary Notions of \\refsect{source-complexity"
      },
      {
        "level": "H1",
        "text": "Proofs and Auxiliary Notions of \\refsect{int-complexity"
      },
      {
        "level": "H1",
        "text": "Proofs of \\refsect{sharing"
      },
      {
        "level": "H1",
        "text": "Part 2: the \\TTAM for the Target Calculus"
      },
      {
        "level": "H1",
        "text": "Part 2: the \\TTAM for \\texorpdfstring{$\\tarcal$"
      },
      {
        "level": "H1",
        "text": "Proofs and Auxiliary Notions of \\refsect{LTAM"
      },
      {
        "level": "H1",
        "text": "Part 1: Outline of the Target Calculus \\texorpdfstring{$\\tarcal$"
      },
      {
        "level": "H1",
        "text": "Part 3: Size Explosion and Sharing for Tuples"
      },
      {
        "level": "H1",
        "text": "Part 2 Preliminaries: Local Environments"
      },
      {
        "level": "H1",
        "text": "Proofs and Auxiliary Notions of \\refsect{intermediate-calculus"
      },
      {
        "level": "H1",
        "text": "Proofs and Auxiliary Notions of \\Cref{sect:source-calculus"
      },
      {
        "level": "H1",
        "text": "Proofs and Auxiliary Notions of \\refsect{TTAM"
      },
      {
        "level": "H1",
        "text": "Implementation in OCaml of the \\TTAM"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15843v1",
    "url": "http://arxiv.org/abs/2507.15843v1"
  },
  {
    "title": "TASI/CERN/KITP Lecture Notes on \"Toward Quantum Computing Gauge Theories of Nature\"",
    "outline": [
      {
        "level": "H1",
        "text": "Introduction\n\\label{sec:introduction"
      },
      {
        "level": "H1",
        "text": "Hamiltonian formulation of gauge theories\n\\label{sec:Hamiltonian"
      },
      {
        "level": "H2",
        "text": "Kogut-Susskind Hamiltonian of lattice gauge theories\n\\label{sec:KS"
      },
      {
        "level": "H3",
        "text": "U(1) lattice gauge theory\n\\label{sec:U(1)"
      },
      {
        "level": "H3",
        "text": "SU(2) lattice gauge theory\n\\label{sec:SU(2)"
      },
      {
        "level": "H3",
        "text": "SU(3) lattice gauge theory\n\\label{sec:SU(3)"
      },
      {
        "level": "H2",
        "text": "Basis choices, Hilbert space, local constraints\n\\label{sec:basis"
      },
      {
        "level": "H3",
        "text": "U(1) lattice gauge theory\n\\label{sec:U(1)-basis"
      },
      {
        "level": "H3",
        "text": "SU(2) lattice gauge theory\n\\label{sec:SU(2)-basis"
      },
      {
        "level": "H3",
        "text": "SU(3) lattice gauge theory\n\\label{sec:SU(3)-basis"
      },
      {
        "level": "H2",
        "text": "On Hamiltonian-simulation methods\n\\label{sec:KS"
      },
      {
        "level": "H1",
        "text": "Quantum computation of gauge theories\n\\label{sec:simulation"
      },
      {
        "level": "H2",
        "text": "Quantum-computing basics\n\\label{sec:QC-basics"
      },
      {
        "level": "H3",
        "text": "Qubits, gates, and circuits\n\\label{sec:qubits"
      },
      {
        "level": "H3",
        "text": "Mapping fermions and bosons\n\\label{sec:mapping"
      },
      {
        "level": "H2",
        "text": "Quantum-simulation steps in nutshell\n\\label{sec:QS-steps"
      },
      {
        "level": "H3",
        "text": "State preparation\n\\label{sec:state-prep"
      },
      {
        "level": "H3",
        "text": "Time evolution\n\\label{sec:evolution"
      },
      {
        "level": "H3",
        "text": "Observable measurement\n\\label{sec:measurements"
      },
      {
        "level": "H2",
        "text": "Time evolution in gauge theories\n\\label{sec:LGT-evolution"
      },
      {
        "level": "H3",
        "text": "In-depth study: (1+1)D U(1) lattice gauge theory\n\\label{sec:U(1)-warm-up"
      },
      {
        "level": "H3",
        "text": "An overview: (3+1)D SU(3) lattice gauge theory\n\\label{sec:QCD"
      },
      {
        "level": "H1",
        "text": "Summary and conclusions\n\\label{sec:summary"
      },
      {
        "level": "H1",
        "text": "Acknowledgment"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15840v1",
    "url": "http://arxiv.org/abs/2507.15840v1"
  },
  {
    "title": "FASTGEN: Fast and Cost-Effective Synthetic Tabular Data Generation with LLMs",
    "outline": [
      {
        "level": "H1",
        "text": "Related Works"
      },
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H1",
        "text": "Sampling Script Generation"
      },
      {
        "level": "H2",
        "text": "Preprocessing"
      },
      {
        "level": "H2",
        "text": "Identify Distribution"
      },
      {
        "level": "H2",
        "text": "Script Generation"
      },
      {
        "level": "H2",
        "text": "Data Generation"
      },
      {
        "level": "H1",
        "text": "Lessons, Limitation and Future Works"
      },
      {
        "level": "H2",
        "text": "Human Feedback for Continuous Improvement"
      },
      {
        "level": "H2",
        "text": "Challenges and Opportunities in LLM-assisted Evaluation"
      },
      {
        "level": "H2",
        "text": "Insights on LLM Behavior"
      },
      {
        "level": "H2",
        "text": "Limitation on Cross-field Relationship"
      },
      {
        "level": "H1",
        "text": "Conclusion"
      },
      {
        "level": "H1",
        "text": "Experiment Settings"
      },
      {
        "level": "H2",
        "text": "Datasets"
      },
      {
        "level": "H2",
        "text": "Algorithm Configuration"
      },
      {
        "level": "H2",
        "text": "Baselines"
      },
      {
        "level": "H1",
        "text": "Evaluation"
      },
      {
        "level": "H2",
        "text": "Diversity"
      },
      {
        "level": "H3",
        "text": "Vocabulary"
      },
      {
        "level": "H3",
        "text": "Inter Sample N-gram Frequency"
      },
      {
        "level": "H2",
        "text": "Realism"
      },
      {
        "level": "H3",
        "text": "Kullback-Leibler Divergence"
      },
      {
        "level": "H3",
        "text": "Optimal Transport"
      },
      {
        "level": "H3",
        "text": "Distance to Closest Record"
      },
      {
        "level": "H2",
        "text": "Exploratory Analysis"
      },
      {
        "level": "H3",
        "text": "Vocabulary"
      },
      {
        "level": "H3",
        "text": "Inter Sample N-gram Frequency"
      },
      {
        "level": "H2",
        "text": "Efficiency Analysis"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15839v1",
    "url": "http://arxiv.org/abs/2507.15839v1"
  },
  {
    "title": "Electron-Transfer and Exchange-Interaction Model of the Ligand Hyperfine Structure of Alkylated Iron-Sulfur Clusters",
    "outline": [
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H1",
        "text": "Theory"
      },
      {
        "level": "H2",
        "text": "Spin Wavefunctions and Hamiltonian"
      },
      {
        "level": "H2",
        "text": "Bound Ligand Case"
      },
      {
        "level": "H2",
        "text": "Radical-Cluster Exchange Interaction"
      },
      {
        "level": "H1",
        "text": "Computational Methodology"
      },
      {
        "level": "H1",
        "text": "Results and Discussion"
      },
      {
        "level": "H1",
        "text": "Conclusion"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15838v1",
    "url": "http://arxiv.org/abs/2507.15838v1"
  },
  {
    "title": "SDSO1 is a Ghost Planetary Nebula Bow Shock in Front of M31",
    "outline": [
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H1",
        "text": "Narrowband Imaging Observations and Data Reduction"
      },
      {
        "level": "H1",
        "text": "Results"
      },
      {
        "level": "H1",
        "text": "Discussion"
      },
      {
        "level": "H2",
        "text": "SDSO1 is a Hypersonic GPN"
      },
      {
        "level": "H2",
        "text": "The SDSO1 GPN Central Star EG Andromedae"
      },
      {
        "level": "H2",
        "text": "Density and ionization of the surrounding ISM"
      },
      {
        "level": "H2",
        "text": "The GPN Tail"
      },
      {
        "level": "H2",
        "text": "GPN Expansion and Energetics"
      },
      {
        "level": "H2",
        "text": "Photoionization by EG And"
      },
      {
        "level": "H2",
        "text": "Shock Models"
      },
      {
        "level": "H2",
        "text": "SDSO1 Bow Shock Structure and Kinematics"
      },
      {
        "level": "H2",
        "text": "Statistics and Fates of the Old PNe and GPNe Populations"
      },
      {
        "level": "H1",
        "text": "Conclusions"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15834v1",
    "url": "http://arxiv.org/abs/2507.15834v1"
  },
  {
    "title": "Look, Focus, Act: Efficient and Robust Robot Learning via Human Gaze and Foveated Vision Transformers",
    "outline": [
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H1",
        "text": "Related Work"
      },
      {
        "level": "H2",
        "text": "Biologically-Inspired Visual Processing"
      },
      {
        "level": "H2",
        "text": "Gaze for Robotics"
      },
      {
        "level": "H1",
        "text": "Method"
      },
      {
        "level": "H2",
        "text": "Data Collection with Eye Tracking"
      },
      {
        "level": "H2",
        "text": "Flow Matching Policy"
      },
      {
        "level": "H2",
        "text": "Policy Architecture"
      },
      {
        "level": "H2",
        "text": "Gaze Prediction"
      },
      {
        "level": "H2",
        "text": "Foveated Tokenization"
      },
      {
        "level": "H1",
        "text": "Experiments"
      },
      {
        "level": "H1",
        "text": "Results"
      },
      {
        "level": "H2",
        "text": "Success Rates"
      },
      {
        "level": "H2",
        "text": "Efficiency"
      },
      {
        "level": "H1",
        "text": "Conclusion"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15833v1",
    "url": "http://arxiv.org/abs/2507.15833v1"
  },
  {
    "title": "Observing Fine-Grained Changes in Jupyter Notebooks During Development Time",
    "outline": [
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H1",
        "text": "Data Collection"
      },
      {
        "level": "H2",
        "text": "Designing Tasks"
      },
      {
        "level": "H3",
        "text": "Data Analysis Task"
      },
      {
        "level": "H3",
        "text": "Machine Learning Task"
      },
      {
        "level": "H2",
        "text": "Choosing Participants"
      },
      {
        "level": "H2",
        "text": "Executing the Experiment"
      },
      {
        "level": "H1",
        "text": "Dataset"
      },
      {
        "level": "H1",
        "text": "Empirical Analysis Methodology"
      },
      {
        "level": "H2",
        "text": "RQ1: Nature of Code Changes"
      },
      {
        "level": "H2",
        "text": "RQ2: The Purposes of Code Changes"
      },
      {
        "level": "H2",
        "text": "RQ3: Changes in Data Science Steps"
      },
      {
        "level": "H1",
        "text": "Acknowledgments"
      },
      {
        "level": "H1",
        "text": "Tooling"
      },
      {
        "level": "H2",
        "text": "Activity Plugin"
      },
      {
        "level": "H2",
        "text": "Server"
      },
      {
        "level": "H2",
        "text": "Post-processing Scripts"
      },
      {
        "level": "H2",
        "text": "Browsing the Notebook Versions"
      },
      {
        "level": "H1",
        "text": "Conclusion"
      },
      {
        "level": "H1",
        "text": "Data Availability"
      },
      {
        "level": "H1",
        "text": "Findings"
      },
      {
        "level": "H2",
        "text": "\\textbf{RQ1:"
      },
      {
        "level": "H2",
        "text": "\\textbf{RQ2:"
      },
      {
        "level": "H2",
        "text": "\\textbf{RQ3:"
      },
      {
        "level": "H3",
        "text": "Stages of different data science steps"
      },
      {
        "level": "H3",
        "text": "Transitions between data science steps"
      },
      {
        "level": "H1",
        "text": "Background and Related Work"
      },
      {
        "level": "H2",
        "text": "Code Evolution in Software Engineering"
      },
      {
        "level": "H2",
        "text": "Coding in Jupyter Notebooks"
      },
      {
        "level": "H1",
        "text": "Discussion"
      },
      {
        "level": "H2",
        "text": "Threats to Validity"
      },
      {
        "level": "H2",
        "text": "Implications"
      },
      {
        "level": "H1",
        "text": "Possible Future Research"
      },
      {
        "level": "H2",
        "text": "Temporal Analysis of the Workflow"
      },
      {
        "level": "H2",
        "text": "Analysis of Code Dynamics"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15831v1",
    "url": "http://arxiv.org/abs/2507.15831v1"
  },
  {
    "title": "AutoWISP: Automated Processing of Wide-Field Color Images",
    "outline": [
      {
        "level": "H1",
        "text": "Discussion"
      },
      {
        "level": "H2",
        "text": "Project PANOPTES"
      },
      {
        "level": "H2",
        "text": "Challenges"
      },
      {
        "level": "H2",
        "text": "Future Endeavors"
      },
      {
        "level": "H3",
        "text": "Browser-user-interface"
      },
      {
        "level": "H3",
        "text": "More features and functionalities"
      },
      {
        "level": "H1",
        "text": "Example Application of AutoWISP"
      },
      {
        "level": "H2",
        "text": "Observations"
      },
      {
        "level": "H2",
        "text": "Results"
      },
      {
        "level": "H2",
        "text": "Example light curves:"
      },
      {
        "level": "H3",
        "text": "GQ Dra"
      },
      {
        "level": "H3",
        "text": "GG Dra"
      },
      {
        "level": "H3",
        "text": "V0551 Dra"
      },
      {
        "level": "H3",
        "text": "TX UMa"
      },
      {
        "level": "H3",
        "text": "GW UMa"
      },
      {
        "level": "H1",
        "text": "Acknowledgements"
      },
      {
        "level": "H3",
        "text": "#1"
      },
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H2",
        "text": "Motivation"
      },
      {
        "level": "H3",
        "text": "Current state of the art:"
      },
      {
        "level": "H2",
        "text": "Breakdown"
      },
      {
        "level": "H1",
        "text": "Methodology"
      },
      {
        "level": "H2",
        "text": "Calibration:"
      },
      {
        "level": "H3",
        "text": "Mask creation"
      },
      {
        "level": "H3",
        "text": "Overscan corrections"
      },
      {
        "level": "H3",
        "text": "Subtraction of bias level and dark current"
      },
      {
        "level": "H3",
        "text": "Flat field corrections are applied"
      },
      {
        "level": "H3",
        "text": "Individual pixel errors are calculated"
      },
      {
        "level": "H2",
        "text": "Source Extraction"
      },
      {
        "level": "H2",
        "text": "Astrometry Based Photometry:"
      },
      {
        "level": "H2",
        "text": "Photometry:"
      },
      {
        "level": "H2",
        "text": "Magnitude Fitting:"
      },
      {
        "level": "H2",
        "text": "Light Curves:"
      },
      {
        "level": "H2",
        "text": "Post Processing:"
      },
      {
        "level": "H3",
        "text": "External Parameter Decorrelation (EPD)"
      },
      {
        "level": "H3",
        "text": "Trend Filtering Algorithm (TFA)"
      },
      {
        "level": "H1",
        "text": "Implementation of AutoWISP"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15830v1",
    "url": "http://arxiv.org/abs/2507.15830v1"
  },
  {
    "title": "Just Ask for Music (JAM): Multimodal and Personalized Natural Language Music Recommendation",
    "outline": [
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H1",
        "text": "Dataset"
      },
      {
        "level": "H1",
        "text": "Methodology"
      },
      {
        "level": "H1",
        "text": "Experimental Setup"
      },
      {
        "level": "H1",
        "text": "Results"
      },
      {
        "level": "H1",
        "text": "Conclusion and Future Work"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15826v1",
    "url": "http://arxiv.org/abs/2507.15826v1"
  },
  {
    "title": "ACS: An interactive framework for conformal selection",
    "outline": [
      {
        "level": "H2",
        "text": "Warm-up: CS as a screening procedure"
      },
      {
        "level": "H2",
        "text": "ACS: the general framework"
      },
      {
        "level": "H2",
        "text": "Theoretical guarantees"
      },
      {
        "level": "H2",
        "text": "Adaptive Conformal Selection"
      },
      {
        "level": "H2",
        "text": "Organization of the paper"
      },
      {
        "level": "H2",
        "text": "Experiments for question answering (QA) datasets"
      },
      {
        "level": "H2",
        "text": "Experiments for chest X-ray report generation"
      },
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H1",
        "text": "Preliminaries"
      },
      {
        "level": "H1",
        "text": "Adaptive conformal selection"
      },
      {
        "level": "H1",
        "text": "Instantiation of ACS"
      },
      {
        "level": "H1",
        "text": "Numerical simulations"
      },
      {
        "level": "H1",
        "text": "Real data application: LLM deployment"
      },
      {
        "level": "H1",
        "text": "Real data application: Drug discovery"
      },
      {
        "level": "H1",
        "text": "Discussion"
      },
      {
        "level": "H2",
        "text": "Reproducibility"
      },
      {
        "level": "H2",
        "text": "Acknowledgments"
      },
      {
        "level": "H2",
        "text": "Simulation setup"
      },
      {
        "level": "H2",
        "text": "ACS with model-refitting: individual base models"
      },
      {
        "level": "H2",
        "text": "ACS with model-refitting: adaptive model selection"
      },
      {
        "level": "H2",
        "text": "Diversified selection"
      },
      {
        "level": "H2",
        "text": "Incorporating new labels"
      },
      {
        "level": "H2",
        "text": "Boosting power"
      },
      {
        "level": "H2",
        "text": "Diversifying selection"
      },
      {
        "level": "H3",
        "text": "Diversity-aware ordering"
      },
      {
        "level": "H2",
        "text": "Incorporating new labels"
      },
      {
        "level": "H2",
        "text": "Adaptive choice of local tests"
      },
      {
        "level": "H2",
        "text": "Problem setup"
      },
      {
        "level": "H2",
        "text": "Background: conformal selection"
      },
      {
        "level": "H2",
        "text": "Related work"
      },
      {
        "level": "H1",
        "text": "Proofs of the main results"
      },
      {
        "level": "H2",
        "text": "Proof of Theorem~\\ref{thm:fdr_control"
      },
      {
        "level": "H1",
        "text": "Deferred proofs"
      },
      {
        "level": "H2",
        "text": "Proof of Lemma~\\ref{lemma:equal_prob"
      },
      {
        "level": "H2",
        "text": "Proof of Proposition~\\ref{prop:diversity"
      },
      {
        "level": "H1",
        "text": "Proof of Additional Lemmas"
      },
      {
        "level": "H2",
        "text": "Proof of Lemma~\\ref{lemma:equal_prob"
      },
      {
        "level": "H2",
        "text": "Proof of Lemma~\\ref{hypergeom-lemma"
      },
      {
        "level": "H1",
        "text": "Additional simulation results"
      },
      {
        "level": "H2",
        "text": "Additional results with individual base models"
      },
      {
        "level": "H2",
        "text": "Model selection"
      },
      {
        "level": "H2",
        "text": "Diversity-aware selection"
      },
      {
        "level": "H2",
        "text": "The effect of $k$"
      },
      {
        "level": "H1",
        "text": "Additional real data results"
      },
      {
        "level": "H2",
        "text": "Additional details and results for LLM deployment"
      },
      {
        "level": "H3",
        "text": "Feature engineering for prediction model training"
      },
      {
        "level": "H3",
        "text": "Additional experimental results"
      },
      {
        "level": "H2",
        "text": "Additional drug discovery results"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15825v1",
    "url": "http://arxiv.org/abs/2507.15825v1"
  },
  {
    "title": "Can Your Model Separate Yolks with a Water Bottle? Benchmarking Physical Commonsense Understanding in Video Generation Models",
    "outline": [
      {
        "level": "H1",
        "text": "Expanded Comparison with Existing Benchmarks"
      },
      {
        "level": "H1",
        "text": "Benchmark Design and Evaluation Details"
      },
      {
        "level": "H2",
        "text": "Prompt Generation and Upsampling"
      },
      {
        "level": "H2",
        "text": "Physical Commonsense Dimensions and Sample Prompts"
      },
      {
        "level": "H2",
        "text": "Evaluation Details"
      },
      {
        "level": "H1",
        "text": "Additional Generation Results and Qualitative Examples"
      },
      {
        "level": "H2",
        "text": "DifficultyBased Prompt Stratification"
      },
      {
        "level": "H2",
        "text": "Qualitative Examples"
      },
      {
        "level": "H2",
        "text": "Model Generation Specifications"
      },
      {
        "level": "H1",
        "text": "User Study Details and Human Evaluation"
      },
      {
        "level": "H1",
        "text": "Effect of Caption Detail on Model Performance: Short vs. Dense Captions"
      },
      {
        "level": "H1",
        "text": "Limitations"
      },
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H1",
        "text": "Related Work"
      },
      {
        "level": "H1",
        "text": "Benchmark"
      },
      {
        "level": "H2",
        "text": "Tested Physical Commonsense Concepts"
      },
      {
        "level": "H2",
        "text": "Construction of Prompts"
      },
      {
        "level": "H2",
        "text": "Evaluation"
      },
      {
        "level": "H1",
        "text": "Experimental Results"
      },
      {
        "level": "H1",
        "text": "Insights and Discussion"
      },
      {
        "level": "H1",
        "text": "Limitations"
      },
      {
        "level": "H1",
        "text": "Conclusion"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15824v1",
    "url": "http://arxiv.org/abs/2507.15824v1"
  },
  {
    "title": "Operationalizing AI for Good: Spotlight on Deployment and Integration of AI Models in Humanitarian Work",
    "outline": [
      {
        "level": "H1",
        "text": "Limitations"
      },
      {
        "level": "H1",
        "text": "Ethical Considerations"
      },
      {
        "level": "H1",
        "text": "Discussion"
      },
      {
        "level": "H1",
        "text": "Implementation and Deployment"
      },
      {
        "level": "H2",
        "text": "Offline Experimentation"
      },
      {
        "level": "H2",
        "text": "Staging Deployment Calibration"
      },
      {
        "level": "H2",
        "text": "Post-Deployment Analysis"
      },
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H1",
        "text": "Partnership Case Study"
      },
      {
        "level": "H2",
        "text": "Partner Details"
      },
      {
        "level": "H2",
        "text": "Problem Scope"
      },
      {
        "level": "H2",
        "text": "Resource Constraints"
      },
      {
        "level": "H1",
        "text": "Appendix"
      },
      {
        "level": "H2",
        "text": "Threshold Tuning across 3 Languages"
      },
      {
        "level": "H2",
        "text": "Categorization Model Performance"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15823v1",
    "url": "http://arxiv.org/abs/2507.15823v1"
  },
  {
    "title": "Do AI models help produce verified bug fixes?",
    "outline": [
      {
        "level": "H1",
        "text": "#1"
      },
      {
        "level": "H2",
        "text": "#1"
      },
      {
        "level": "H3",
        "text": "#1"
      },
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H1",
        "text": "Terminology"
      },
      {
        "level": "H1",
        "text": "Research questions"
      },
      {
        "level": "H1",
        "text": "Related work"
      },
      {
        "level": "H2",
        "text": "Surveys of automated program repair"
      },
      {
        "level": "H2",
        "text": "Developer studies and tool adoption"
      },
      {
        "level": "H2",
        "text": "LLM-based repair techniques"
      },
      {
        "level": "H2",
        "text": "LLMs and formal verification"
      },
      {
        "level": "H1",
        "text": "Tool stack"
      },
      {
        "level": "H1",
        "text": "Threats to validity"
      },
      {
        "level": "H2",
        "text": "Goal W: In turning a buggy program into a correct one, is it fruitful to use an LLM?"
      },
      {
        "level": "H2",
        "text": "Goal H: If programmers do use an LLM for debugging, what is an effective process?"
      },
      {
        "level": "H2",
        "text": "General observations"
      },
      {
        "level": "H2",
        "text": "Advice for LLM usage"
      },
      {
        "level": "H2",
        "text": "Lessons on the use of LLMs for debugging"
      },
      {
        "level": "H2",
        "text": "Contributions"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15822v1",
    "url": "http://arxiv.org/abs/2507.15822v1"
  },
  {
    "title": "Euclid preparation: Expected constraints on initial conditions",
    "outline": [
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H1",
        "text": "{\\it Euclid"
      },
      {
        "level": "H2",
        "text": "Spectroscopic galaxy clustering"
      },
      {
        "level": "H2",
        "text": "Photometric galaxy clustering and weak lensing"
      },
      {
        "level": "H2",
        "text": "Probe combination"
      },
      {
        "level": "H1",
        "text": "Expected constraints on $\\Omega_K$"
      },
      {
        "level": "H1",
        "text": "Expected constraints on the scalar spectral index and its running"
      },
      {
        "level": "H1",
        "text": "Expected constraints on isocurvature contribution"
      },
      {
        "level": "H2",
        "text": "Motivation and background"
      },
      {
        "level": "H2",
        "text": "CDI models we consider and their observational aspects"
      },
      {
        "level": "H2",
        "text": "{\\em Euclid"
      },
      {
        "level": "H1",
        "text": "Expected constraints on primordial non-Gaussianity"
      },
      {
        "level": "H2",
        "text": "Fisher analysis"
      },
      {
        "level": "H3",
        "text": "Matter bispectrum"
      },
      {
        "level": "H3",
        "text": "Galaxy power spectrum and bispectrum"
      },
      {
        "level": "H3",
        "text": "Fisher forecasts"
      },
      {
        "level": "H2",
        "text": "Bayesian analysis (\\borg)"
      },
      {
        "level": "H1",
        "text": "Beyond slow roll: searches for primordial features"
      },
      {
        "level": "H1",
        "text": "Conclusions"
      },
      {
        "level": "H1",
        "text": "Combination with current and future CMB measurements"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15819v1",
    "url": "http://arxiv.org/abs/2507.15819v1"
  },
  {
    "title": "The Capacity of Semantic Private Information Retrieval with Colluding Servers",
    "outline": [
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H1",
        "text": "Problem Formulation"
      },
      {
        "level": "H1",
        "text": "Main Result"
      },
      {
        "level": "H1",
        "text": "Corollaries and Discussions"
      },
      {
        "level": "H1",
        "text": "Achievable Scheme"
      },
      {
        "level": "H1",
        "text": "Illustrative Examples"
      },
      {
        "level": "H2",
        "text": "Example 1"
      },
      {
        "level": "H2",
        "text": "Example 2"
      },
      {
        "level": "H1",
        "text": "Privacy Proof"
      },
      {
        "level": "H1",
        "text": "Converse Proof"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15818v1",
    "url": "http://arxiv.org/abs/2507.15818v1"
  },
  {
    "title": "Federated Split Learning with Improved Communication and Storage Efficiency",
    "outline": [
      {
        "level": "H1",
        "text": "References Cited"
      },
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H1",
        "text": "Related Works"
      },
      {
        "level": "H1",
        "text": "Federated and Split Learning Paradigms"
      },
      {
        "level": "H2",
        "text": "The Distributed SGD Problem"
      },
      {
        "level": "H2",
        "text": "Federated and Split Learning"
      },
      {
        "level": "H2",
        "text": "Challenges"
      },
      {
        "level": "H1",
        "text": "Communication and Storage Efficient Federated Split Learning"
      },
      {
        "level": "H2",
        "text": "Auxiliary Network"
      },
      {
        "level": "H2",
        "text": "CSE-FSL"
      },
      {
        "level": "H1",
        "text": "Performance Analysis"
      },
      {
        "level": "H2",
        "text": "Convergence Analysis"
      },
      {
        "level": "H2",
        "text": "Communication and Storage Analysis"
      },
      {
        "level": "H1",
        "text": "Experimental Results"
      },
      {
        "level": "H2",
        "text": "Experiment Setup"
      },
      {
        "level": "H2",
        "text": "Accuracy Comparison"
      },
      {
        "level": "H2",
        "text": "Impact of Auxiliary Network Architectures"
      },
      {
        "level": "H2",
        "text": "Communication Load"
      },
      {
        "level": "H2",
        "text": "Storage Analysis"
      },
      {
        "level": "H2",
        "text": "Comprehensive Analysis"
      },
      {
        "level": "H1",
        "text": "Conclusions"
      },
      {
        "level": "H1",
        "text": "Proof of \\Cref{{prop:conv_c"
      },
      {
        "level": "H1",
        "text": "Proof of \\Cref{{prop:conv_s"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15816v1",
    "url": "http://arxiv.org/abs/2507.15816v1"
  },
  {
    "title": "LLM Economist: Large Population Models and Mechanism Design in Multi-Agent Generative Simulacra",
    "outline": [
      {
        "level": "H1",
        "text": "Acknowledgement"
      },
      {
        "level": "H1",
        "text": "LLM Economist"
      },
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H1",
        "text": "Economic Background"
      },
      {
        "level": "H1",
        "text": "Optimal Tax Rate Derivation for Piecewise Linear Tax"
      },
      {
        "level": "H2",
        "text": "Basic Framework"
      },
      {
        "level": "H2",
        "text": "Mechanical Tax Increase"
      },
      {
        "level": "H2",
        "text": "Social Welfare Effect"
      },
      {
        "level": "H2",
        "text": "Behavioral Response"
      },
      {
        "level": "H2",
        "text": "Optimality Condition"
      },
      {
        "level": "H2",
        "text": "Key Equation Derivation"
      },
      {
        "level": "H2",
        "text": "Continuous Limit Case"
      },
      {
        "level": "H1",
        "text": "Background Economic Theory"
      },
      {
        "level": "H2",
        "text": "Top Income Tax Rate~(\\citet{saez2001using"
      },
      {
        "level": "H2",
        "text": "Non-Linear Income Tax Rate~(\\citet{saez2001using"
      },
      {
        "level": "H2",
        "text": "Piecewise Linear Income Tax Rate"
      },
      {
        "level": "H1",
        "text": "Worker Personas"
      },
      {
        "level": "H1",
        "text": "Simulation"
      },
      {
        "level": "H1",
        "text": "Experiments"
      },
      {
        "level": "H2",
        "text": "Basic components"
      },
      {
        "level": "H3",
        "text": "In-Context Reinforcement Learning"
      },
      {
        "level": "H2",
        "text": "Planner's Social Welfare Optimization"
      },
      {
        "level": "H3",
        "text": "Multiple Worker Utility Optimization"
      },
      {
        "level": "H2",
        "text": "Workers' Utility Optimization"
      },
      {
        "level": "H2",
        "text": "LLM Economist"
      },
      {
        "level": "H2",
        "text": "Tax-Planning Optimization"
      },
      {
        "level": "H2",
        "text": "Tax Policy Evaluation"
      },
      {
        "level": "H2",
        "text": "Voting Simulacra"
      },
      {
        "level": "H1",
        "text": "Related Work"
      },
      {
        "level": "H1",
        "text": "Discussion"
      },
      {
        "level": "H1",
        "text": "Preliminaries"
      },
      {
        "level": "H1",
        "text": "Scaling"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15815v1",
    "url": "http://arxiv.org/abs/2507.15815v1"
  },
  {
    "title": "Hyperelastic nature of the Hoek-Brown criterion",
    "outline": [
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H2",
        "text": "Notations"
      },
      {
        "level": "H1",
        "text": "Hyperelasticity coupled to plasticity"
      },
      {
        "level": "H2",
        "text": "Thermodynamics of perfect plasticity"
      },
      {
        "level": "H2",
        "text": "Beyond the linear approximation"
      },
      {
        "level": "H1",
        "text": "Hyperelastic enrichment of perfect plasticity"
      },
      {
        "level": "H2",
        "text": "Mapping thermodynamics to observables"
      },
      {
        "level": "H2",
        "text": "The yield criterion transformation"
      },
      {
        "level": "H1",
        "text": "Responses on typical tests"
      },
      {
        "level": "H2",
        "text": "Hydrostatic tests"
      },
      {
        "level": "H2",
        "text": "Triaxial compression test with a confining pressure"
      },
      {
        "level": "H2",
        "text": "Cyclic triaxial test"
      },
      {
        "level": "H2",
        "text": "Comparison with the linear elasto-plastic model"
      },
      {
        "level": "H2",
        "text": "Comparison with an experimental uniaxial compression test"
      },
      {
        "level": "H1",
        "text": "Finite element simulation example"
      },
      {
        "level": "H1",
        "text": "Conclusion"
      },
      {
        "level": "H1",
        "text": "Acknowledgements"
      },
      {
        "level": "H1",
        "text": "Hoek--Brown type quadratic yield criteria"
      },
      {
        "level": "H1",
        "text": "Numerical integration procedure of the model"
      },
      {
        "level": "H3",
        "text": "Increment of the plastic strain on the smooth portion"
      },
      {
        "level": "H3",
        "text": "Increment of the plastic strain at the apex"
      },
      {
        "level": "H3",
        "text": "Expression of the stress and of the consistent tangent operator"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15813v1",
    "url": "http://arxiv.org/abs/2507.15813v1"
  },
  {
    "title": "Diffusion models for multivariate subsurface generation and efficient probabilistic inversion",
    "outline": [
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H1",
        "text": "Methodology"
      },
      {
        "level": "H2",
        "text": "Diffusion modeling"
      },
      {
        "level": "H2",
        "text": "Diffusion Posterior Sampling (DPS)"
      },
      {
        "level": "H3",
        "text": "Corrected Diffusion Posterior Sampling (CDPS)"
      },
      {
        "level": "H2",
        "text": "Multivariate diffusion modeling"
      },
      {
        "level": "H2",
        "text": "Performance assessment"
      },
      {
        "level": "H2",
        "text": "Code implementation"
      },
      {
        "level": "H1",
        "text": "Results"
      },
      {
        "level": "H2",
        "text": "Unconditonal modeling"
      },
      {
        "level": "H2",
        "text": "Inverse modeling using CDPS"
      },
      {
        "level": "H3",
        "text": "Linear conditioning results"
      },
      {
        "level": "H3",
        "text": "Nonlinear inversion results"
      },
      {
        "level": "H2",
        "text": "Computational performances"
      },
      {
        "level": "H1",
        "text": "Discussion"
      },
      {
        "level": "H1",
        "text": "Conclusions"
      },
      {
        "level": "H1",
        "text": "Code availability"
      },
      {
        "level": "H1",
        "text": "\\LARGE Appendix"
      },
      {
        "level": "H1",
        "text": "Additional assessment of prior modeling performance"
      },
      {
        "level": "H2",
        "text": "Geostatistical metrics"
      },
      {
        "level": "H2",
        "text": "Training efficiency"
      },
      {
        "level": "H1",
        "text": "Conditioning on multiple data types"
      },
      {
        "level": "H1",
        "text": "CDPS implementation with DDPM and DDIM"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15809v1",
    "url": "http://arxiv.org/abs/2507.15809v1"
  },
  {
    "title": "True Multimodal In-Context Learning Needs Attention to the Visual Context",
    "outline": [
      {
        "level": "H1",
        "text": "DARA as a constrained version of LoRA"
      },
      {
        "level": "H1",
        "text": "TrueMICL"
      },
      {
        "level": "H1",
        "text": "More Details of Experimental Setup"
      },
      {
        "level": "H2",
        "text": "MLLMs"
      },
      {
        "level": "H2",
        "text": "Datasets and Evaluation Metrics"
      },
      {
        "level": "H2",
        "text": "Baselines"
      },
      {
        "level": "H1",
        "text": "More Experimental Analysis"
      },
      {
        "level": "H2",
        "text": "Discussion on the Performance between DARA and LoRA"
      },
      {
        "level": "H2",
        "text": "Closed-source model performances"
      },
      {
        "level": "H2",
        "text": "Amounts of params in DARA"
      },
      {
        "level": "H2",
        "text": "Effect of Prompt Design"
      },
      {
        "level": "H1",
        "text": "Conclusions"
      },
      {
        "level": "H1",
        "text": "Acknowledgment"
      },
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H1",
        "text": "Related Work"
      },
      {
        "level": "H1",
        "text": "Experiments"
      },
      {
        "level": "H2",
        "text": "Experimental Setup"
      },
      {
        "level": "H2",
        "text": "Result Analysis on TrueMICL"
      },
      {
        "level": "H2",
        "text": "Visualization of the DARA's Reallocation Effects"
      },
      {
        "level": "H2",
        "text": "Result Analysis on Standard VL Datasets"
      },
      {
        "level": "H2",
        "text": "Ablation Study"
      },
      {
        "level": "H1",
        "text": "Methodology"
      },
      {
        "level": "H2",
        "text": "Dynamic Attention Reallocation"
      },
      {
        "level": "H2",
        "text": "TrueMICL, a MICL-dedicated Dataset"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15807v1",
    "url": "http://arxiv.org/abs/2507.15807v1"
  },
  {
    "title": "1D Vlasov Simulations of QED Cascades Over Pulsar Polar Caps",
    "outline": [
      {
        "level": "H1",
        "text": "Conclusions"
      },
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H1",
        "text": "Overview of the Physical Model"
      },
      {
        "level": "H2",
        "text": "Radiation and Radiative Reaction"
      },
      {
        "level": "H2",
        "text": "Magnetic Pair Production"
      },
      {
        "level": "H1",
        "text": "1D simulations of QED cascade"
      },
      {
        "level": "H2",
        "text": "Simulations of the RS Model"
      },
      {
        "level": "H2",
        "text": "Simulations of the SCLF Model"
      },
      {
        "level": "H1",
        "text": "Discussion"
      },
      {
        "level": "H2",
        "text": "Energy Budget and Surface Heating by Returning Particles"
      },
      {
        "level": "H2",
        "text": "The Spatiotemporal and Spectral Structures of the Electric Field Energy"
      },
      {
        "level": "H2",
        "text": "Scope of Quantitative Estimates in Millisecond Pulsars"
      },
      {
        "level": "H1",
        "text": "Numerical methods"
      },
      {
        "level": "H2",
        "text": "1D VlasovMaxwell System"
      },
      {
        "level": "H2",
        "text": "Validation: Two Stream Instability"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15804v1",
    "url": "http://arxiv.org/abs/2507.15804v1"
  },
  {
    "title": "Hypergraphs on high dimensional time series sets using signature transform",
    "outline": [
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H1",
        "text": "Introduction: Computing hypergraph on a multivariate time series using signature transform."
      },
      {
        "level": "H2",
        "text": "Motivation and Background"
      },
      {
        "level": "H2",
        "text": "Related Work."
      },
      {
        "level": "H2",
        "text": "The signature transform."
      },
      {
        "level": "H2",
        "text": "Hypergraph on multivariate time series."
      },
      {
        "level": "H1",
        "text": "Modifications of the algorithm."
      },
      {
        "level": "H2",
        "text": "Fitting the new data format."
      },
      {
        "level": "H2",
        "text": "Bringing randomness in the algorithm."
      },
      {
        "level": "H1",
        "text": "Experiments"
      },
      {
        "level": "H1",
        "text": "Conclusion and perspectives."
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15802v1",
    "url": "http://arxiv.org/abs/2507.15802v1"
  },
  {
    "title": "Fluid Antenna-enabled Near-Field Integrated Sensing, Computing and Semantic Communication for Emerging Applications",
    "outline": [
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H2",
        "text": "List of Notations:"
      },
      {
        "level": "H1",
        "text": "System Model"
      },
      {
        "level": "H2",
        "text": "Signal Transmission Model"
      },
      {
        "level": "H2",
        "text": "Communication Model"
      },
      {
        "level": "H2",
        "text": "Sensing Model"
      },
      {
        "level": "H1",
        "text": "Performance Measures"
      },
      {
        "level": "H2",
        "text": "Sensing"
      },
      {
        "level": "H2",
        "text": "Semantic Communication"
      },
      {
        "level": "H2",
        "text": "Computing"
      },
      {
        "level": "H1",
        "text": "Joint Design of FA-enabled NF-ISCSC System"
      },
      {
        "level": "H2",
        "text": "Problem Formulation"
      },
      {
        "level": "H2",
        "text": "Joint Beamforming and Computation Optimisation"
      },
      {
        "level": "H2",
        "text": "FA Position Optimisation"
      },
      {
        "level": "H3",
        "text": "Benchmark method (second-order Taylor expansion)"
      },
      {
        "level": "H3",
        "text": "Projected BFGS"
      },
      {
        "level": "H2",
        "text": "Semantic Extraction Ratio Optimisation"
      },
      {
        "level": "H1",
        "text": "Simulation Results"
      },
      {
        "level": "H2",
        "text": "Algorithm Performance"
      },
      {
        "level": "H2",
        "text": "Semantic Communication Performance"
      },
      {
        "level": "H2",
        "text": "Sensing Performance"
      },
      {
        "level": "H2",
        "text": "Computing Performance"
      },
      {
        "level": "H1",
        "text": "Conclusion and Future Direction"
      },
      {
        "level": "H1",
        "text": "Proof of FIM"
      },
      {
        "level": "H1",
        "text": "Proof and Derivation of Equation \\eqref{fim"
      },
      {
        "level": "H1",
        "text": "Analysis of FIM for a Point Target"
      },
      {
        "level": "H1",
        "text": "Convergence Analysis"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15800v1",
    "url": "http://arxiv.org/abs/2507.15800v1"
  },
  {
    "title": "Quantum logic operations and algorithms in a single 25-level atomic qudit",
    "outline": [
      {
        "level": "H1",
        "text": "System Hamiltonian, Frequencies, and Transition Strengths"
      },
      {
        "level": "H2",
        "text": "System Hamiltonian"
      },
      {
        "level": "H2",
        "text": "Transition Frequencies"
      },
      {
        "level": "H3",
        "text": "Ramsey-Based Calibration Scheme"
      },
      {
        "level": "H3",
        "text": "Finding detunings from Ramsey accumulated phase"
      },
      {
        "level": "H3",
        "text": "Frequency calibration uncertainty"
      },
      {
        "level": "H2",
        "text": "Transition Strengths"
      },
      {
        "level": "H1",
        "text": "NBOP Initialisation"
      },
      {
        "level": "H1",
        "text": "25-level SPAM Error Calculations"
      },
      {
        "level": "H2",
        "text": "Decay from meta-stable states"
      },
      {
        "level": "H2",
        "text": "Off-resonant driving"
      },
      {
        "level": "H2",
        "text": "Bright/dark state discrimination"
      },
      {
        "level": "H1",
        "text": "Noise Measurements and Modelling"
      },
      {
        "level": "H2",
        "text": "Magnetic Field Noise"
      },
      {
        "level": "H3",
        "text": "Laser Frequency Noise Decoherence Cancellation"
      },
      {
        "level": "H2",
        "text": "Laser Noise"
      },
      {
        "level": "H2",
        "text": "A/C Line Signal"
      },
      {
        "level": "H1",
        "text": "Towards High-Fidelity Qudits"
      },
      {
        "level": "H2",
        "text": "High-Fidelity SPAM"
      },
      {
        "level": "H2",
        "text": "High-contrast qudit Ramsey control"
      },
      {
        "level": "H2",
        "text": "Qudit control with known noise levels"
      },
      {
        "level": "H1",
        "text": "Pulse Sequences and Encodings for Gates and Algorithms"
      },
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H1",
        "text": "Qudit encoding and SPAM"
      },
      {
        "level": "H1",
        "text": "Multi-level coherence"
      },
      {
        "level": "H1",
        "text": "Quantum processing with virtual qubits"
      },
      {
        "level": "H1",
        "text": "Outlook"
      },
      {
        "level": "H1",
        "text": "Acknowledgements"
      },
      {
        "level": "H1",
        "text": "METHODS"
      },
      {
        "level": "H2",
        "text": "Experimental setup"
      },
      {
        "level": "H2",
        "text": "Narrow-band optical pumping"
      },
      {
        "level": "H2",
        "text": "State choices for encoding SPAM, qudits, and virtual qubits"
      },
      {
        "level": "H2",
        "text": "Qudit Ramsey-type experiment - analytic expressions"
      },
      {
        "level": "H2",
        "text": "Monte-Carlo simulation of noisy multi-level system"
      },
      {
        "level": "H2",
        "text": "Unitary decomposition with Star-Topology constraint"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15799v1",
    "url": "http://arxiv.org/abs/2507.15799v1"
  },
  {
    "title": "Deterministic Quantum Search via Recursive Oracle Expansion",
    "outline": [
      {
        "level": "H1",
        "text": "Deterministic Quantum Search"
      },
      {
        "level": "H1",
        "text": "Conclusion"
      },
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H1",
        "text": "Analysis and Discussion"
      },
      {
        "level": "H2",
        "text": "Algorithm Complexity"
      },
      {
        "level": "H2",
        "text": "Partial Database Search"
      },
      {
        "level": "H2",
        "text": "Implementation Complexity"
      },
      {
        "level": "H2",
        "text": "Discussion and Future Work"
      },
      {
        "level": "H1",
        "text": "Grover's Algorithm"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15797v1",
    "url": "http://arxiv.org/abs/2507.15797v1"
  },
  {
    "title": "Challenges of Trustworthy Federated Learning: What's Done, Current Trends and Remaining Work",
    "outline": [
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H1",
        "text": "Introduction to Federated Learning"
      },
      {
        "level": "H2",
        "text": "\\paco{Why?"
      },
      {
        "level": "H2",
        "text": "\\paco{How?"
      },
      {
        "level": "H1",
        "text": "Challenges of Trustworthy Federated Learning"
      },
      {
        "level": "H2",
        "text": "Requirement 1: Human agency and oversight"
      },
      {
        "level": "H2",
        "text": "Requirement 2: Technical robustness and safety"
      },
      {
        "level": "H2",
        "text": "Requirement 3: Privacy and data governance"
      },
      {
        "level": "H2",
        "text": "Requirement 4: Transparency"
      },
      {
        "level": "H2",
        "text": "Requirement 5: Diversity, non-discrimination \\& fairness"
      },
      {
        "level": "H2",
        "text": "Requirement 6: Societal and environmental well-being"
      },
      {
        "level": "H2",
        "text": "Requirement 7: Accountability"
      },
      {
        "level": "H1",
        "text": "Discussion and Dimension Frontiers"
      },
      {
        "level": "H2",
        "text": "Discussion"
      },
      {
        "level": "H2",
        "text": "Collective Intelligence as a Dimension Frontier"
      },
      {
        "level": "H1",
        "text": "Conclusions"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15796v1",
    "url": "http://arxiv.org/abs/2507.15796v1"
  },
  {
    "title": "Regularized Low-Rank Adaptation for Few-Shot Organ Segmentation",
    "outline": [
      {
        "level": "H1",
        "text": "Experiments"
      },
      {
        "level": "H2",
        "text": "Setup"
      },
      {
        "level": "H2",
        "text": "Results"
      },
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H3",
        "text": "\\ackname"
      },
      {
        "level": "H3",
        "text": "\\discintname"
      },
      {
        "level": "H1",
        "text": "Conclusions"
      },
      {
        "level": "H1",
        "text": "Methods"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15793v1",
    "url": "http://arxiv.org/abs/2507.15793v1"
  },
  {
    "title": "Decadal evolution of a repeating fast radio burst source",
    "outline": [
      {
        "level": "H1",
        "text": "Observation Campaign and Data Reduction"
      },
      {
        "level": "H1",
        "text": "DM Variation"
      },
      {
        "level": "H1",
        "text": "Burst Rate and Energy Distribution"
      },
      {
        "level": "H1",
        "text": "Time-Domain Analysis"
      },
      {
        "level": "H2",
        "text": "Active Periodicity and Time Difference Algorithms"
      },
      {
        "level": "H2",
        "text": "Short Timescale Period Search"
      },
      {
        "level": "H2",
        "text": "Long Timescale Period Search"
      },
      {
        "level": "H1",
        "text": "A Comprehensive Analysis"
      },
      {
        "level": "H1",
        "text": "Morphology"
      },
      {
        "level": "H1",
        "text": "Polarization Analysis"
      },
      {
        "level": "H1",
        "text": "Physical Origin of the Evolution of DM and RM of FRB 20121102A"
      },
      {
        "level": "H2",
        "text": "Observation of FRB 20121102A"
      },
      {
        "level": "H2",
        "text": "Evolution of DM and RM from a Young Supernova Remnant"
      },
      {
        "level": "H2",
        "text": "Extra DM from Pair Injection by Enhanced Wind"
      },
      {
        "level": "H1",
        "text": "Contribution of Binary Star Orbital Motion to the DM Evolution"
      },
      {
        "level": "H2",
        "text": "Data availability"
      },
      {
        "level": "H2",
        "text": "Code availability"
      },
      {
        "level": "H1",
        "text": "Supplementary Table"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15790v1",
    "url": "http://arxiv.org/abs/2507.15790v1"
  },
  {
    "title": "Small LLMs Do Not Learn a Generalizable Theory of Mind via Reinforcement Learning",
    "outline": [
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H1",
        "text": "Related Work"
      },
      {
        "level": "H1",
        "text": "Methodology"
      },
      {
        "level": "H2",
        "text": "Datasets"
      },
      {
        "level": "H3",
        "text": "Training Datasets"
      },
      {
        "level": "H2",
        "text": "Evaluation Datasets"
      },
      {
        "level": "H2",
        "text": "Reward Function Design"
      },
      {
        "level": "H2",
        "text": "Training Algorithm: REINFORCE++"
      },
      {
        "level": "H1",
        "text": "Experiments and Results"
      },
      {
        "level": "H2",
        "text": "Experimental Setup"
      },
      {
        "level": "H2",
        "text": "Results"
      },
      {
        "level": "H3",
        "text": "RL Performance on In-Distribution Tasks"
      },
      {
        "level": "H3",
        "text": "RL Performance on Out-Of-Distribution Tasks"
      },
      {
        "level": "H3",
        "text": "Performance on Different ToM Orders"
      },
      {
        "level": "H2",
        "text": "Performance On Task Variations"
      },
      {
        "level": "H3",
        "text": "Training Behavior Analysis"
      },
      {
        "level": "H1",
        "text": "Discussion"
      },
      {
        "level": "H1",
        "text": "Conclusion"
      },
      {
        "level": "H1",
        "text": "Acknowledgements"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15788v1",
    "url": "http://arxiv.org/abs/2507.15788v1"
  },
  {
    "title": "Missing Physics Discovery through Fully Differentiable Finite Element-Based Machine Learning",
    "outline": [
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H1",
        "text": "Results"
      },
      {
        "level": "H2",
        "text": "Framework"
      },
      {
        "level": "H3",
        "text": "Operator Learning over Finite Element Spaces"
      },
      {
        "level": "H2",
        "text": "Learning Materials Constitutive Models"
      },
      {
        "level": "H3",
        "text": "Learning from Loads in Displacement-Controlled Experiments"
      },
      {
        "level": "H3",
        "text": "Learning from Displacements in Load-Controlled Experiments"
      },
      {
        "level": "H3",
        "text": "Zero Shot Inference with a Foundational Model"
      },
      {
        "level": "H2",
        "text": "Learning in Transient Thermodynamics Problems"
      },
      {
        "level": "H3",
        "text": "Learning Thermal Properties from Temperature Measurements"
      },
      {
        "level": "H1",
        "text": "Discussion and Conclusions"
      },
      {
        "level": "H1",
        "text": "Methods"
      },
      {
        "level": "H2",
        "text": "Coupling between Firedrake and PyTorch/JAX"
      },
      {
        "level": "H2",
        "text": "Simulating Displacement-Controlled Uniaxial Experiments"
      },
      {
        "level": "H2",
        "text": "Simulating Load-Controlled Brazilian Disc Experiements"
      },
      {
        "level": "H2",
        "text": "Simulating Torsional Behaviour in Thin Plates"
      },
      {
        "level": "H2",
        "text": "Simulating Transient Heat Conduction Experiments"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15787v1",
    "url": "http://arxiv.org/abs/2507.15787v1"
  },
  {
    "title": "Graph Attention Specialized Expert Fusion Model for Node Classification: Based on Cora and Pubmed Datasets",
    "outline": [
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H1",
        "text": "Literature Review"
      },
      {
        "level": "H2",
        "text": "Traditional Approaches to Node Classification"
      },
      {
        "level": "H2",
        "text": "Graph Neural Networks"
      },
      {
        "level": "H3",
        "text": "Graph Convolutional Networks (GCNs)"
      },
      {
        "level": "H3",
        "text": "Graph Attention Networks (GATs)"
      },
      {
        "level": "H2",
        "text": "Multi-hop and Higher-order Graph Neural Networks"
      },
      {
        "level": "H3",
        "text": "Multi-hop GNNs"
      },
      {
        "level": "H3",
        "text": "APPNP and SGC"
      },
      {
        "level": "H2",
        "text": "Ensemble Methods for Node Classification"
      },
      {
        "level": "H3",
        "text": "Model Ensembles"
      },
      {
        "level": "H3",
        "text": "Expert Models"
      },
      {
        "level": "H2",
        "text": "Optimal Transport for Representation Learning"
      },
      {
        "level": "H3",
        "text": "Wasserstein Distance in Machine Learning"
      },
      {
        "level": "H3",
        "text": "Gromov-Wasserstein Distance"
      },
      {
        "level": "H3",
        "text": "Applications to Graph Representation Learning"
      },
      {
        "level": "H2",
        "text": "Cross-domain and Transfer Learning in Graph Neural Networks"
      },
      {
        "level": "H2",
        "text": "Performance Comparison"
      },
      {
        "level": "H2",
        "text": "Research Gaps and Our Contribution"
      },
      {
        "level": "H1",
        "text": "Optimization of GCN"
      },
      {
        "level": "H2",
        "text": "Model Architecture Comparison"
      },
      {
        "level": "H2",
        "text": "Performance Comparison and Analysis"
      },
      {
        "level": "H2",
        "text": "The Necessity of Introducing Attention Mechanisms"
      },
      {
        "level": "H1",
        "text": "The Introduction of GAT"
      },
      {
        "level": "H2",
        "text": "Abstract of Attention Mechanisms in Graphs"
      },
      {
        "level": "H2",
        "text": "Combination of Graph Convolution and Attention"
      },
      {
        "level": "H3",
        "text": "Node-level Attention Implemented by GATConv"
      },
      {
        "level": "H3",
        "text": "Implementation of Multi-hop Mechanism"
      },
      {
        "level": "H3",
        "text": "Hop-level Attention"
      },
      {
        "level": "H3",
        "text": "Enhanced Components for Stable Training"
      },
      {
        "level": "H2",
        "text": "Performance Comparison of Different Models"
      },
      {
        "level": "H3",
        "text": "Overall Performance"
      },
      {
        "level": "H3",
        "text": "Category-specific Differences"
      },
      {
        "level": "H3",
        "text": "Explanations"
      },
      {
        "level": "H2",
        "text": "Next Improvement Direction: Expert Fusion Mechanism"
      },
      {
        "level": "H3",
        "text": "Expert Division of Labor"
      },
      {
        "level": "H3",
        "text": "Adaptive Fusion Strategy"
      },
      {
        "level": "H3",
        "text": "Mechanism Rationale"
      },
      {
        "level": "H3",
        "text": "Future Outlook"
      },
      {
        "level": "H1",
        "text": "Optimizing GAT: Introduction of Expert Fusion Model"
      },
      {
        "level": "H2",
        "text": "Design Principle of Expert Fusion Model"
      },
      {
        "level": "H2",
        "text": "Implementation of Expert Models"
      },
      {
        "level": "H2",
        "text": "Design of Fusion Strategies"
      },
      {
        "level": "H3",
        "text": "Advantages of the Expert Fusion Model"
      },
      {
        "level": "H3",
        "text": "Generalization Potential"
      },
      {
        "level": "H2",
        "text": "Result Analysis"
      },
      {
        "level": "H3",
        "text": "Balance Analysis"
      },
      {
        "level": "H3",
        "text": "Precision-Recall Tradeoff"
      },
      {
        "level": "H3",
        "text": "Stability Quantification"
      },
      {
        "level": "H3",
        "text": "Multi-expert Weighted Fusion Mechanism"
      },
      {
        "level": "H1",
        "text": "Optimizing Expert Fusion: Introduction of Wasserstein-Rubinstein Distance"
      },
      {
        "level": "H2",
        "text": "Theoretical Foundation of Wasserstein-Rubinstein Distance"
      },
      {
        "level": "H2",
        "text": "WR Distance for Model Representation Alignment"
      },
      {
        "level": "H3",
        "text": "Representation Alignment Across Models"
      },
      {
        "level": "H3",
        "text": "Category-Specific Distance Optimization"
      },
      {
        "level": "H2",
        "text": "Enhanced Fusion Architecture with WR Guidance"
      },
      {
        "level": "H3",
        "text": "WR Distance Computation Module"
      },
      {
        "level": "H3",
        "text": "Class-Aware Projection Networks"
      },
      {
        "level": "H3",
        "text": "Dynamic Fusion Weight Adjustment"
      },
      {
        "level": "H2",
        "text": "Experimental Results and Analysis"
      },
      {
        "level": "H3",
        "text": "Performance Improvements"
      },
      {
        "level": "H3",
        "text": "Stability Analysis"
      },
      {
        "level": "H3",
        "text": "Ablation Study"
      },
      {
        "level": "H2",
        "text": "Visualization of Learned Representations"
      },
      {
        "level": "H1",
        "text": "Conclusion"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15784v1",
    "url": "http://arxiv.org/abs/2507.15784v1"
  },
  {
    "title": "Density control of multi-agent swarms via bio-inspired leader-follower plasticity",
    "outline": [
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H1",
        "text": "Problem Statement"
      },
      {
        "level": "H2",
        "text": "Problem statement"
      },
      {
        "level": "H1",
        "text": "Bio-inspired Control"
      },
      {
        "level": "H2",
        "text": "Design of the leaders' velocity field"
      },
      {
        "level": "H2",
        "text": "Design of the reacting term"
      },
      {
        "level": "H2",
        "text": "Stability analysis"
      },
      {
        "level": "H1",
        "text": "Numerical Validation"
      },
      {
        "level": "H2",
        "text": "Bimodal regulation"
      },
      {
        "level": "H2",
        "text": "Robustness analysis"
      },
      {
        "level": "H1",
        "text": "Agent-based Model"
      },
      {
        "level": "H1",
        "text": "Higher-Dimensional Extension"
      },
      {
        "level": "H2",
        "text": "Bio-inspired Control"
      },
      {
        "level": "H2",
        "text": "Stability Analysis"
      },
      {
        "level": "H2",
        "text": "Numerical validation"
      },
      {
        "level": "H1",
        "text": "Conclusions"
      },
      {
        "level": "H1",
        "text": "Non-plastic followers at steady-state"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15781v1",
    "url": "http://arxiv.org/abs/2507.15781v1"
  },
  {
    "title": "Reservoir Computing as a Language Model",
    "outline": [
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H1",
        "text": "Task Formulation and Dataset"
      },
      {
        "level": "H1",
        "text": "Background and Model Architectures"
      },
      {
        "level": "H2",
        "text": "Traditional Reservoir Computing"
      },
      {
        "level": "H2",
        "text": "Attention-Enhanced Reservoir Computing"
      },
      {
        "level": "H2",
        "text": "Transformer Architectures"
      },
      {
        "level": "H1",
        "text": "Architectures"
      },
      {
        "level": "H1",
        "text": "Training"
      },
      {
        "level": "H1",
        "text": "Methodology"
      },
      {
        "level": "H1",
        "text": "Results"
      },
      {
        "level": "H2",
        "text": "Evaluation Metrics and Analysis"
      },
      {
        "level": "H3",
        "text": "\\textit{N"
      },
      {
        "level": "H3",
        "text": "Mathematical Formulation"
      },
      {
        "level": "H2",
        "text": "\\textit{N"
      },
      {
        "level": "H2",
        "text": "Inference Time Comparison"
      },
      {
        "level": "H1",
        "text": "Conclusion"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15779v1",
    "url": "http://arxiv.org/abs/2507.15779v1"
  },
  {
    "title": "Stabilizing Knowledge, Promoting Reasoning: Dual-Token Constraints for RLVR",
    "outline": [
      {
        "level": "H1",
        "text": "Introduction"
      },
      {
        "level": "H1",
        "text": "Preliminary"
      },
      {
        "level": "H2",
        "text": "Group Relative Policy Optimization"
      },
      {
        "level": "H2",
        "text": "Decouple Clip and Dynamic Sampling Policy Optimization"
      },
      {
        "level": "H1",
        "text": "Method"
      },
      {
        "level": "H2",
        "text": "Critical Tokens Identification via Response-level Entropy"
      },
      {
        "level": "H3",
        "text": "Response-Level Entropy Statistics"
      },
      {
        "level": "H2",
        "text": "Token-Level Disentangled Training"
      },
      {
        "level": "H3",
        "text": "Participatory Training of Low-Entropy Tokens"
      },
      {
        "level": "H3",
        "text": "Our Method"
      },
      {
        "level": "H1",
        "text": "Experiments"
      },
      {
        "level": "H2",
        "text": "Setup"
      },
      {
        "level": "H2",
        "text": "Main Results"
      },
      {
        "level": "H2",
        "text": "Ablation Study"
      },
      {
        "level": "H2",
        "text": "Analysis"
      },
      {
        "level": "H3",
        "text": "Impact of Different KL Weights"
      },
      {
        "level": "H3",
        "text": "Impact of Clip Ranges on Different Token Types"
      },
      {
        "level": "H3",
        "text": "Visualization of RL Optimization Regions"
      },
      {
        "level": "H3",
        "text": "Mutual Enhancement Between Math RL and Code RL"
      },
      {
        "level": "H1",
        "text": "Problem-level accuracy comparison"
      },
      {
        "level": "H1",
        "text": "Related Work"
      },
      {
        "level": "H2",
        "text": "Reinforcement Learning for Large Language Models"
      },
      {
        "level": "H2",
        "text": "Critical Token Analysis in RL for Reasoning"
      },
      {
        "level": "H1",
        "text": "Conclusion"
      },
      {
        "level": "H1",
        "text": "Acknowledgments"
      },
      {
        "level": "H1",
        "text": "Experimental Details"
      },
      {
        "level": "H2",
        "text": "Dataset"
      },
      {
        "level": "H3",
        "text": "Code Domain"
      },
      {
        "level": "H3",
        "text": "Mathematics Domain"
      },
      {
        "level": "H1",
        "text": "Additional Experimental Results"
      },
      {
        "level": "H2",
        "text": "Impact of Clip Ranges on High-Entropy Tokens"
      },
      {
        "level": "H1",
        "text": "Problem-level accuracy comparison"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15778v1",
    "url": "http://arxiv.org/abs/2507.15778v1"
  },
  {
    "title": "Dissociating model architectures from inference computations",
    "outline": [
      {
        "level": "H2",
        "text": "Introduction"
      },
      {
        "level": "H2",
        "text": "Methods"
      },
      {
        "level": "H2",
        "text": "Results"
      },
      {
        "level": "H2",
        "text": "General discussion"
      }
    ],
    "query": "natural language processing",
    "arxiv_id": "2507.15776v1",
    "url": "http://arxiv.org/abs/2507.15776v1"
  }
]